{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjn4DA6RjPfi",
        "outputId": "83ed8d78-582f-4cb7-981e-da6d8af5c6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for Website: {'student_id': 1742491419, 'risk_probability': np.float64(0.29), 'at_risk': 0, 'final_grade': None, 'alcohol_index': 3, 'insights': {'dynamic_risk': {'probability': '0.29', 'label': 'Low', 'threshold': '0.55'}, 'top_interaction': 'age + G2: -0.00 impact', 'peer_benchmark': {'studytime': 'Yours: 2 vs. Peer Avg: 1.9', 'absences': 'Yours: 10 vs. Peer Avg: 3.9', 'G1': 'Yours: 12 vs. Peer Avg: 10.4'}, 'what_if': {'current': '0.29', 'study_plus_1': '0.30', 'absences_minus_5': '0.30'}, 'trajectory': [np.int64(12), np.int64(10), np.int64(8)], 'risk_profile': {'Academic Effort': '0.0%', 'Lifestyle': '0.0%', 'Support': '0.0%'}, 'interventions': [], 'resilience': ['famrel: 0.00 reduction', 'parents_education: 0.00 reduction'], 'anomalies': ['No unusual patterns']}}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import shap\n",
        "import joblib\n",
        "import sqlite3\n",
        "\n",
        "model = joblib.load(\"student_model.joblib\")\n",
        "scaler = joblib.load(\"scaler.joblib\")\n",
        "encoder = joblib.load(\"encoder.joblib\")\n",
        "\n",
        "data_path = \"/content/student-combined.csv\"\n",
        "data = pd.read_csv(data_path, sep=';')\n",
        "\n",
        "number_columns = [\n",
        "    \"age\", \"Medu\", \"Fedu\", \"traveltime\", \"studytime\", \"failures\",\n",
        "    \"famrel\", \"freetime\", \"goout\", \"Dalc\", \"Walc\", \"health\", \"absences\",\n",
        "    \"G1\", \"G2\", \"study_effort\", \"alcohol_index\", \"parents_education\",\n",
        "    \"grade_change\", \"high_absences\"\n",
        "]\n",
        "word_columns = [\n",
        "    \"school\", \"sex\", \"famsize\", \"Pstatus\", \"Mjob\", \"Fjob\", \"reason\",\n",
        "    \"guardian\", \"schoolsup\", \"famsup\", \"paid\", \"activities\", \"nursery\",\n",
        "    \"higher\", \"internet\", \"romantic\"\n",
        "]\n",
        "\n",
        "def add_new_columns(data):\n",
        "    \"\"\"Add engineered features to the dataset.\"\"\"\n",
        "    # Check if 'G3' exists before calculating 'final_grade'\n",
        "    if 'G3' in data.columns:\n",
        "        data[\"final_grade\"] = (data[\"G1\"] + data[\"G2\"] + data[\"G3\"]) / 3\n",
        "        data[\"final_grade\"] = data[\"final_grade\"].round(2)\n",
        "    #If G3 column doesn't exist\n",
        "    else:\n",
        "        #Set final_grade to nan\n",
        "        data['final_grade'] = np.nan\n",
        "\n",
        "    data[\"alcohol_index\"] = data[\"Dalc\"] + data[\"Walc\"]\n",
        "    data[\"parents_education\"] = data[\"Medu\"] + data[\"Fedu\"]\n",
        "    data[\"grade_change\"] = data[\"G2\"] - data[\"G1\"]\n",
        "    avg_absences = data[\"absences\"].mean()\n",
        "    data[\"high_absences\"] = data[\"absences\"].apply(lambda x: 1 if x > avg_absences else 0)\n",
        "    data[\"study_effort\"] = data[\"studytime\"] * (5 - data[\"traveltime\"])\n",
        "    return data\n",
        "\n",
        "data = add_new_columns(data)\n",
        "\n",
        "X_scaled = scaler.transform(data[number_columns])\n",
        "clusters = KMeans(n_clusters=3, random_state=42).fit_predict(X_scaled)\n",
        "data[\"cluster\"] = clusters\n",
        "\n",
        "def process_user_data(user_input):\n",
        "    \"\"\"Process user input, predict risk, and generate insights.\"\"\"\n",
        "    # Convert user input to DataFrame\n",
        "    user_df = pd.DataFrame([user_input])\n",
        "\n",
        "    # Add engineered features\n",
        "    user_df = add_new_columns(user_df)\n",
        "\n",
        "    # Preprocess for model\n",
        "    user_numbers = scaler.transform(user_df[number_columns])\n",
        "    user_words = encoder.transform(user_df[word_columns])\n",
        "    user_ready = np.hstack((user_numbers, user_words))\n",
        "\n",
        "    # Predict with Random Forest\n",
        "    risk_prob = model.predict_proba(user_ready)[0][1]\n",
        "    at_risk = model.predict(user_ready)[0]\n",
        "\n",
        "    # SHAP analysis\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    predicted_class = model.predict(user_ready)[0]\n",
        "    shap_values = explainer.shap_values(user_ready)[predicted_class]\n",
        "    shap_contributions = dict(zip(number_columns + list(encoder.get_feature_names_out(word_columns)), shap_values))\n",
        "\n",
        "    insights = {}\n",
        "\n",
        "    # 1.\n",
        "    base_threshold = 0.5\n",
        "    threshold_adjust = 0.1 * (user_df[\"parents_education\"].iloc[0] / 8)\n",
        "    dynamic_threshold = base_threshold + threshold_adjust\n",
        "    risk_label = \"High\" if risk_prob > dynamic_threshold else \"Low\" if risk_prob < 0.3 else \"Medium\"\n",
        "    insights[\"dynamic_risk\"] = {\"probability\": f\"{risk_prob:.2f}\", \"label\": risk_label, \"threshold\": f\"{dynamic_threshold:.2f}\"}\n",
        "\n",
        "    # 2.\n",
        "    shap_interactions = explainer.shap_interaction_values(user_ready)\n",
        "    shap_interactions = shap_interactions[predicted_class]\n",
        "\n",
        "    if shap_interactions.ndim > 2:\n",
        "        shap_interactions = shap_interactions.sum(axis=tuple(range(2, shap_interactions.ndim)))\n",
        "\n",
        "    if shap_interactions.ndim == 2:\n",
        "        top_interaction_idx = np.argmax(np.abs(shap_interactions).sum(axis=0))\n",
        "        feature1, feature2 = np.unravel_index(top_interaction_idx, shap_interactions.shape)\n",
        "        feature_names = number_columns + list(encoder.get_feature_names_out(word_columns))\n",
        "        insights[\"top_interaction\"] = f\"{feature_names[feature1]} + {feature_names[feature2]}: {shap_interactions[feature1, feature2]:.2f} impact\"\n",
        "    else:\n",
        "        insights[\"top_interaction\"] = \"No significant interactions detected.\"\n",
        "\n",
        "    # 3.\n",
        "    user_cluster = KMeans(n_clusters=3, random_state=42).fit(X_scaled).predict(user_numbers)[0]\n",
        "    peer_avg = data[data[\"cluster\"] == user_cluster][[\"studytime\", \"absences\", \"G1\"]].mean()\n",
        "    insights[\"peer_benchmark\"] = {\n",
        "        \"studytime\": f\"Yours: {user_df['studytime'].iloc[0]} vs. Peer Avg: {peer_avg['studytime']:.1f}\",\n",
        "        \"absences\": f\"Yours: {user_df['absences'].iloc[0]} vs. Peer Avg: {peer_avg['absences']:.1f}\",\n",
        "        \"G1\": f\"Yours: {user_df['G1'].iloc[0]} vs. Peer Avg: {peer_avg['G1']:.1f}\"\n",
        "    }\n",
        "\n",
        "    # 4.\n",
        "    def what_if(user_df, feature, new_value):\n",
        "        mod_df = user_df.copy()\n",
        "        mod_df[feature] = new_value\n",
        "        mod_numbers = scaler.transform(mod_df[number_columns])\n",
        "        mod_words = encoder.transform(mod_df[word_columns])\n",
        "        mod_ready = np.hstack((mod_numbers, mod_words))\n",
        "        return model.predict_proba(mod_ready)[0][1]\n",
        "\n",
        "    what_if_study = what_if(user_df, \"studytime\", user_df[\"studytime\"].iloc[0] + 1)\n",
        "    what_if_absences = what_if(user_df, \"absences\", max(0, user_df[\"absences\"].iloc[0] - 5))\n",
        "    insights[\"what_if\"] = {\n",
        "        \"current\": f\"{risk_prob:.2f}\",\n",
        "        \"study_plus_1\": f\"{what_if_study:.2f}\",\n",
        "        \"absences_minus_5\": f\"{what_if_absences:.2f}\"\n",
        "    }\n",
        "\n",
        "    # 5.\n",
        "    trajectory = [user_df[\"G1\"].iloc[0], user_df[\"G2\"].iloc[0]]\n",
        "    if \"G3\" in user_df:\n",
        "        trajectory.append(user_df[\"G3\"].iloc[0])\n",
        "    else:\n",
        "        trajectory.append(trajectory[-1] + (trajectory[-1] - trajectory[-2]))\n",
        "    insights[\"trajectory\"] = trajectory\n",
        "\n",
        "    # 6.\n",
        "    categories = {\n",
        "        \"Academic Effort\": [\"studytime\", \"failures\", \"study_effort\"],\n",
        "        \"Lifestyle\": [\"Dalc\", \"Walc\", \"goout\", \"alcohol_index\"],\n",
        "        \"Support\": [\"famrel\", \"parents_education\"]\n",
        "    }\n",
        "    risk_profile = {}\n",
        "    total_shap = np.sum(np.abs(list(shap_contributions.values())))\n",
        "    for category, feats in categories.items():\n",
        "        contrib = np.sum([shap_contributions.get(feat, 0) for feat in feats if feat in shap_contributions])\n",
        "        risk_profile[category] = max(0, contrib) / total_shap * 100 if total_shap > 0 else 0\n",
        "    insights[\"risk_profile\"] = {k: f\"{v:.1f}%\" for k, v in risk_profile.items()}\n",
        "\n",
        "    # 7.\n",
        "    interventions = [\n",
        "        (\"studytime\", user_df[\"studytime\"].iloc[0] + 1, \"Study +1 hr\"),\n",
        "        (\"absences\", max(0, user_df[\"absences\"].iloc[0] - 3), \"Attend 3 more classes\")\n",
        "    ]\n",
        "    impact_scores = []\n",
        "    for feat, new_val, label in interventions:\n",
        "        new_risk = what_if(user_df, feat, new_val)\n",
        "        impact = risk_prob - new_risk\n",
        "        if impact > 0:\n",
        "            impact_scores.append(f\"{label}: -{impact:.2f}\")\n",
        "    insights[\"interventions\"] = impact_scores\n",
        "\n",
        "    # 8.\n",
        "    resilience = {}\n",
        "    for k, v in shap_contributions.items():\n",
        "        value_to_compare = v[0] if isinstance(v, np.ndarray) else v\n",
        "\n",
        "        if value_to_compare < 0 and k in [\"famrel\", \"parents_education\", \"schoolsup\"]:\n",
        "            resilience[k] = v\n",
        "    insights[\"resilience\"] = [f\"{k}: {-v[0]:.2f} reduction\" for k, v in resilience.items()] if resilience else [\"No major resilience factors\"]\n",
        "\n",
        "    # 10.\n",
        "    anomalies = []\n",
        "    if user_df[\"G1\"].iloc[0] > 12 and user_df[\"absences\"].iloc[0] > data[\"absences\"].mean():\n",
        "        anomalies.append(\"High grades but rising absences\")\n",
        "    insights[\"anomalies\"] = anomalies if anomalies else [\"No unusual patterns\"]\n",
        "\n",
        "    result = {\n",
        "        \"student_id\": int(pd.Timestamp.now().timestamp()),  # Unique ID\n",
        "        \"risk_probability\": risk_prob,\n",
        "        \"at_risk\": int(at_risk),\n",
        "        \"final_grade\": user_df[\"final_grade\"].iloc[0] if \"G3\" in user_df else None,\n",
        "        \"alcohol_index\": int(user_df[\"alcohol_index\"].iloc[0]),\n",
        "        \"insights\": insights\n",
        "    }\n",
        "    return result\n",
        "\n",
        "user_input = {\n",
        "    \"school\": \"GP\", \"sex\": \"F\", \"age\": 17, \"famsize\": \"GT3\", \"Pstatus\": \"T\",\n",
        "    \"Medu\": 2, \"Fedu\": 2, \"Mjob\": \"services\", \"Fjob\": \"services\", \"reason\": \"course\",\n",
        "    \"guardian\": \"mother\", \"traveltime\": 2, \"studytime\": 2, \"failures\": 0,\n",
        "    \"schoolsup\": \"yes\", \"famsup\": \"no\", \"paid\": \"no\", \"activities\": \"yes\",\n",
        "    \"nursery\": \"yes\", \"higher\": \"yes\", \"internet\": \"yes\", \"romantic\": \"no\",\n",
        "    \"famrel\": 4, \"freetime\": 3, \"goout\": 2, \"Dalc\": 1, \"Walc\": 2, \"health\": 5,\n",
        "    \"absences\": 10, \"G1\": 12, \"G2\": 10  # G3 optional\n",
        "}\n",
        "\n",
        "# Process the user data\n",
        "result = process_user_data(user_input)\n",
        "\n",
        "def save_to_database(result):\n",
        "    conn = sqlite3.connect(\"student_features.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS user_predictions (\n",
        "            student_id INTEGER PRIMARY KEY, risk_probability REAL, at_risk INTEGER,\n",
        "            final_grade REAL, alcohol_index INTEGER\n",
        "        )\n",
        "    ''')\n",
        "    cursor.execute('''\n",
        "        INSERT OR REPLACE INTO user_predictions (student_id, risk_probability, at_risk, final_grade, alcohol_index)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "    ''', (result[\"student_id\"], result[\"risk_probability\"], result[\"at_risk\"], result[\"final_grade\"], result[\"alcohol_index\"]))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "save_to_database(result)\n",
        "\n",
        "print(\"Result for Website:\", result)"
      ]
    }
  ]
}